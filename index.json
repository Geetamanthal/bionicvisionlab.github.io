[{"authors":["beyeler_michael"],"categories":null,"content":"Michael Beyeler directs the Bionic Vision Lab at UC Santa Barbara.\nHe received a PhD in Computer Science from UC Irvine as well as a BS in Electrical Engineering and a MS in Biomedical Engineering from ETH Zurich, Switzerland. Before joining the faculty at UCSB, he completed a postdoctoral fellowship in the labs of Ione Fine (Psychology, Institute for Neuroengineering) and Ariel Rokem (eScience Institute) at the University of Washington, where he developed computational models of bionic vision.\n","date":1570742503,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1570742503,"objectID":"a30d046c7e5376f816dc02725b57ccf2","permalink":"https://bionicvisionlab.org/authors/beyeler_michael/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/beyeler_michael/","section":"authors","summary":"Michael Beyeler directs the Bionic Vision Lab at UC Santa Barbara.\nHe received a PhD in Computer Science from UC Irvine as well as a BS in Electrical Engineering and a MS in Biomedical Engineering from ETH Zurich, Switzerland. Before joining the faculty at UCSB, he completed a postdoctoral fellowship in the labs of Ione Fine (Psychology, Institute for Neuroengineering) and Ariel Rokem (eScience Institute) at the University of Washington, where he developed computational models of bionic vision.","tags":null,"title":"Michael Beyeler","type":"authors"},{"authors":["kasowski_justin"],"categories":null,"content":"Justin Kasowksi transferred to UC Santa Barbara in 2016 after receiving associates degrees in Biological Sciences and Chemistry from Santa Barbara City College. In 2018, he graduated UCSB with a degree in Molecular, Cellular, and Developmental Biology.\nHe is pursuing his PhD under Dr. Michael Beyeler in the Bionic Vision Lab, where he utilizes virtual reality and computer vision to model the perceptual experience of retinal prosthesis patients.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"a48875e7e0a562c5912f6ba595424697","permalink":"https://bionicvisionlab.org/authors/kasowski_justin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/kasowski_justin/","section":"authors","summary":"Justin Kasowksi transferred to UC Santa Barbara in 2016 after receiving associates degrees in Biological Sciences and Chemistry from Santa Barbara City College. In 2018, he graduated UCSB with a degree in Molecular, Cellular, and Developmental Biology.\nHe is pursuing his PhD under Dr. Michael Beyeler in the Bionic Vision Lab, where he utilizes virtual reality and computer vision to model the perceptual experience of retinal prosthesis patients.","tags":null,"title":"Justin Kasowski","type":"authors"},{"authors":["lam_vy"],"categories":null,"content":"Ly Vam is an undergraduate student in the Department of Molecular, Cellular, and Development Biology at the University of California, Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2d89c4b1d7034db6a3601fc01c589af7","permalink":"https://bionicvisionlab.org/authors/lam_vy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/lam_vy/","section":"authors","summary":"Ly Vam is an undergraduate student in the Department of Molecular, Cellular, and Development Biology at the University of California, Santa Barbara.","tags":null,"title":"Vy Lam","type":"authors"},{"authors":["raghulan_rashi"],"categories":null,"content":"Rashi Raghulan is an undergraduate student in the Department of Molecular, Cellular, and Development Biology at the University of California, Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"5d2f80621a3c5169ac1de1887b567090","permalink":"https://bionicvisionlab.org/authors/raghulan_rashi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/raghulan_rashi/","section":"authors","summary":"Rashi Raghulan is an undergraduate student in the Department of Molecular, Cellular, and Development Biology at the University of California, Santa Barbara.","tags":null,"title":"Rashi Raghulan","type":"authors"},{"authors":["tharanipathy_archita"],"categories":null,"content":"Archita Tharanipathy is currently a second-year undergraduate student pursuing a Biochemistry and Molecular Biology degree at the University of California, Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"00ecd230533145fad54b92080220d125","permalink":"https://bionicvisionlab.org/authors/tharanipathy_archita/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/tharanipathy_archita/","section":"authors","summary":"Archita Tharanipathy is currently a second-year undergraduate student pursuing a Biochemistry and Molecular Biology degree at the University of California, Santa Barbara.","tags":null,"title":"Archita Tharanipathy","type":"authors"},{"authors":null,"categories":null,"content":"What would the world look like with a bionic eye?\nThis graduate course will introduce students to the multidisciplinary field of bionic vision, with an emphasis on both the computer science and neuroscience of the field.\nThe course will give an overview of current bionic eye technology designed to restore vision to people living with incurable blindness. Students will be exposed to the neuroscience of the human visual system, key engineering concepts for designing a brain-computer interface, and computational principles underlying the encoding of a visual scene into an artificial stimulus that the brain can interpret. We will cover recent advances in theory and applications, and discuss outstanding challenges with existing devices. The course will conclude with a team project giving students the opportunity to gain hands-on experience of working on open problems in the field using methods and tools best suited to their scientific background.\nThe course is targeted to a diverse audience spanning from computer science (human factors, computer vision, neural networks) to psychology (vision, psychophysics) and brain sciences (computational neuroscience, neuroengineering).\n","date":1572480000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572480000,"objectID":"e575d5ab26bf85a2b9d88aa8cefe5cd2","permalink":"https://bionicvisionlab.org/teaching/2020-winter-cs291i/","publishdate":"2019-10-31T00:00:00Z","relpermalink":"/teaching/2020-winter-cs291i/","section":"teaching","summary":"This graduate course will introduce students to the multidisciplinary field of bionic vision, with an emphasis on both the computer science and neuroscience of the field.","tags":["human-computer interaction","computational neuroscience","visual psychophysics","neuroengineering"],"title":"CS 291I: Bionic Vision","type":"teaching"},{"authors":["Michael Beyeler","Geoffrey M. Boynton","Ione Fine","Ariel Rokem"],"categories":[],"content":"","date":1570742503,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570742503,"objectID":"630c44461f17ba74859ff8fc47a5b6bd","permalink":"https://bionicvisionlab.org/publication/2019-optimal-surgical-placement/","publishdate":"2019-10-10T14:21:43-07:00","relpermalink":"/publication/2019-optimal-surgical-placement/","section":"publication","summary":"We systematically explored the space of possible implant configurations to make recommendations for optimal intraocular positioning of Argus II.","tags":["neuroengineering","retinal implants","computational models","retinitis pigmentosa","retinal implant surgery"],"title":"Model-based recommendations for optimal surgical placement of epiretinal implants","type":"publication"},{"authors":null,"categories":null,"content":"Despite the increasing clinical and commercial use of retinal implants, the perceptual experience of sight recovery (SR) patients is surprisingly poorly understood.\nA common misconception in the field is that each electrode in an array can be thought of as a ‘pixel’ in an image; to generate a complex visual experience, one then simply needs to turn on the right combination of pixels.\nHowever, almost all SR technologies are likely to suffer from perceptual distortions and subsequent loss of information due to interactions between the technology and the underlying neurophysiology.\nThe goal of this project is to characterize these distortions psychophysically, and to develop a computational model that predicts what a patient should see for any given input stimulus.\n","date":1570060800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570060800,"objectID":"ba5fa69f72b3505988d005912a425275","permalink":"https://bionicvisionlab.org/research/0-visual-modeling/","publishdate":"2019-10-03T00:00:00Z","relpermalink":"/research/0-visual-modeling/","section":"research","summary":"Clinical studies have demonstrated that the vision provided by current SR devices differs substantially from normal sight.","tags":["computational neuroscience","visual psychophysics","computational models"],"title":"What would the world look like with a bionic eye?","type":"research"},{"authors":null,"categories":null,"content":"Our lack of understanding of multi-electrode interactions severely limits current stimulation protocols. For example, current Argus II protocols simply attempt to minimize electric field interactions by maximizing phase delays across electrodes using ‘time-multiplexing’. The assumption is that single-electrode percepts act as atomic ‘building blocks’ of patterned vision. However, these building blocks often fail to assemble into more complex percepts.\nThe goal of this project is therefore to develop new stimulation strategies that minimize perceptual distortions.\n","date":1569974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569974400,"objectID":"63a49ce091f31ff634ace90a3b7c5471","permalink":"https://bionicvisionlab.org/research/1-optimize-stimulation/","publishdate":"2019-10-02T00:00:00Z","relpermalink":"/research/1-optimize-stimulation/","section":"research","summary":"Rather than predicting perceptual distortions, one needs to solve the inverse problem: What is the best stimulus to generate a desired visual percept?","tags":["computer vision","machine learning","neuroengineering","data science"],"title":"How can we design more effective stimulation strategies?","type":"research"},{"authors":null,"categories":null,"content":"Embedding a computational model that can predict the perceptual distortions encountered by sight restoration (SR) patients in virtual reality (VR) will enable sighted subjects to act as virtual patients in real-world tasks. This will allow us to test novel stimulation strategies in high-throughput experiments. Strategies that result in good VR performance will then be validated in real SR patients.\nFor example, rather than aiming to ‘restore natural vision’, there is potential merit in borrowing computer vision algorithms as preprocessing techniques to maximize the usefulness of prosthetic vision. Edge enhancement and contrast maximization are already routinely used in Argus II. In the future, more sophisticated techniques such as low-level image enhancements and visual saliency based transforms could further improve visual performance.\n","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"5d07c563c9daf78e1945a87f9ab55a11","permalink":"https://bionicvisionlab.org/research/2-virtual-patients/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/research/2-virtual-patients/","section":"research","summary":"Novel stimulation strategies can be tested on sighted subjects viewing a simulation of prosthetic vision in virtual/augmented reality.","tags":["virtual reality","augmented reality","visual psychophysics"],"title":"How can virtual patients improve performance of real sight recovery patients?","type":"research"},{"authors":["Bingni W. Brunton","Michael Beyeler"],"categories":null,"content":"","date":1563321600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563321600,"objectID":"43b69a7df75a2dada5a23a4fe3f8f960","permalink":"https://bionicvisionlab.org/publication/2019-data-driven-models-human-neuroscience-neuroengineering/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2019-data-driven-models-human-neuroscience-neuroengineering/","section":"publication","summary":"In this review, we provide an accessible primer to modern modeling approaches and highlight recent data-driven discoveries in the domains of neuroimaging, single-neuron and neuronal population responses, and device neuroengineering.","tags":["neuroscience","neuroengineering","data science","computational models"],"title":"Data-driven models in human neuroscience and neuroengineering","type":"publication"},{"authors":["Michael Beyeler"],"categories":[],"content":"A new article appeared in PCMag to celebrate the inauguration of the Bionic Vision Lab at UCSB:\n Bionic vision might sound like science fiction, but Dr. Michael Beyeler is working on just that.\nOriginally from Switzerland, Dr. Beyeler is wrapping up his postdoctoral fellow at the University of Washington before moving to the University of California Santa Barbara this fall to head up the newly formed Bionic Vision Lab in the Departments of Computer Science and Psychological \u0026amp; Brain Sciences.\nWe spoke with him about this \u0026ldquo;deep fascination with the brain\u0026rdquo; and how he hopes his work will eventually be able to restore vision to the blind. Here are edited and condensed excerpts from our conversation.\n Read the full article here.\n","date":1562689740,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562689753,"objectID":"00c60f07f684f1b3efbeb9fa775c1b01","permalink":"https://bionicvisionlab.org/post/2019-07-pcmag/","publishdate":"2019-07-09T09:29:00-07:00","relpermalink":"/post/2019-07-pcmag/","section":"post","summary":"Michael Beyeler recently sat down with PCMag to talk about bionic vision and his move to UC Santa Barbara.","tags":[],"title":"PCMag: Restoring vision with bionic eyes - no longer science fiction","type":"post"},{"authors":["Michael Beyeler","Emily L. Rounds","Kristofor D. Carlson","Nikil Dutt","Jeffrey L. Krichmar"],"categories":null,"content":"","date":1561593600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561593600,"objectID":"bbcd0bf9d8bf5b4421dda0e383b60bd0","permalink":"https://bionicvisionlab.org/publication/2019-neural-correlates-sparse-coding-dimensionality-reduction/","publishdate":"2019-06-27T00:00:00Z","relpermalink":"/publication/2019-neural-correlates-sparse-coding-dimensionality-reduction/","section":"publication","summary":"Brains face the fundamental challenge of extracting relevant information from high-dimensional external stimuli in order to form the neural basis that can guide an organism's behavior and its interaction with the world. One potential approach to addressing this challenge is to reduce the number of variables required to represent a particular input space (i.e., dimensionality reduction). We review compelling evidence that a range of neuronal responses can be understood as an emergent property of nonnegative sparse coding (NSC)—a form of efficient population coding due to dimensionality reduction and sparsity constraints.","tags":["computational models","sparse coding","population coding","dimensionality reduction","nonnegative matrix factorization"],"title":"Neural correlates of sparse coding and dimensionality reduction","type":"publication"},{"authors":["Michael Beyeler","Devyani Nanduri","James D. Weiland","Ariel Rokem","Geoffrey M. Boynton","Ione Fine"],"categories":null,"content":"","date":1561334400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561334400,"objectID":"2dd7c8662626103dafead1ce078e67a2","permalink":"https://bionicvisionlab.org/publication/2019-axon-map-model/","publishdate":"2019-06-24T00:00:00Z","relpermalink":"/publication/2019-axon-map-model/","section":"publication","summary":"We show that the perceptual experience of retinal implant users can be accurately predicted using a computational model that simulates each individual patient’s retinal ganglion axon pathways.","tags":["neuroengineering","retinal implants","computational models","retinitis pigmentosa","biomedical engineering","pattern vision","perception"],"title":"A model of ganglion axon pathways accounts for percepts elicited by retinal implants","type":"publication"},{"authors":["Michael Beyeler"],"categories":null,"content":"","date":1558310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558310400,"objectID":"590205e420483d3eb975cab6dcf29af1","permalink":"https://bionicvisionlab.org/publication/2019-biophysical-model-axonal-stimulation/","publishdate":"2019-05-20T00:00:00Z","relpermalink":"/publication/2019-biophysical-model-axonal-stimulation/","section":"publication","summary":"To investigate the effect of axonal stimulation on the retinal response, we developed a computational model of a small population of morphologically and biophysically detailed retinal ganglion cells, and simulated their response to epiretinal electrical stimulation. We found that activation thresholds of ganglion cell somas and axons varied systematically with both stimulus pulse duration and electrode-retina distance. These findings have important implications for the improvement of stimulus encoding methods for epiretinal prostheses.","tags":["neuroengineering","retinal implants","computational models","retinitis pigmentosa","biomedical engineering","spiking neural networks"],"title":"Biophysical model of axonal stimulation in epiretinal visual prostheses","type":"publication"},{"authors":["Michael Beyeler"],"categories":null,"content":"","date":1557446400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557446400,"objectID":"bdb5d890074ce8a33df96462da08c953","permalink":"https://bionicvisionlab.org/publication/2019-retinal-sheet-transplants/","publishdate":"2019-05-10T00:00:00Z","relpermalink":"/publication/2019-retinal-sheet-transplants/","section":"publication","summary":"A Commentary on: Detailed Visual Cortical Responses Generated by Retinal Sheet Transplants in Rats with Severe Retinal Degeneration by Foik, A. T., Lean, G. A., Scholl, L. R., McLelland, B. T., Mathur, A., Aramant, R. B., et al. (2018). J. Neurosci. 38, 10709–10724. doi: 10.1523/JNEUROSCI.1279-18.2018","tags":["neuroengineering","retinal sheet transplants"],"title":"Commentary: Detailed visual cortical responses generated by retinal sheet transplants in rats with severe retinal degeneration","type":"publication"},{"authors":["Ting-Shou Chou","Hirak J. Kashyap","Jinwei Xing","Stanislav Listopad","Emily L. Rounds","Michael Beyeler","Nikil Dutt","Jeffrey L. Krichmar"],"categories":null,"content":"","date":1531440000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531440000,"objectID":"4139e2680a25a36a0f14e370e72e1352","permalink":"https://bionicvisionlab.org/publication/2018-carlsim4/","publishdate":"2018-07-13T00:00:00Z","relpermalink":"/publication/2018-carlsim4/","section":"publication","summary":"We have developed CARLsim 4, a user-friendly SNN library written in C++ that can simulate large biologically detailed neural networks. Improving on the efficiency and scalability of earlier releases, the present release allows for the simulation using multiple GPUs and multiple CPU cores concurrently in a heterogeneous computing cluster. Benchmarking results demonstrate simulation of 8.6 million neurons and 0.48 billion synapses using 4 GPUs and up to 60x speedup for multi-GPU implementations over a single-threaded CPU implementation, making CARLsim 4 well-suited for large-scale SNN models in the presence of real-time constraints.","tags":["computational models","spiking neural networks","CARLsim","GPU","parallel programming","C++"],"title":"CARLsim 4: An open source library for large scale, biologically detailed spiking neural network simulation using heterogeneous clusters","type":"publication"},{"authors":["Michael Beyeler","Ariel Rokem","Geoffrey M. Boynton","Ione Fine"],"categories":null,"content":"","date":1503360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503360000,"objectID":"82c721904459e434fcac59d3e13ec296","permalink":"https://bionicvisionlab.org/publication/2017-learning-to-see-again/","publishdate":"2017-08-22T00:00:00Z","relpermalink":"/publication/2017-learning-to-see-again/","section":"publication","summary":"The goal of this review is to summarize the vast basic science literature on developmental and adult cortical plasticity with an emphasis on how this literature might relate to the field of prosthetic vision.","tags":["neuroengineering","retinal implants","cortical plasticity","perceptual learning","retinitis pigmentosa","macular degeneration","biomedical engineering"],"title":"Learning to see again: Biological constraints on cortical plasticity and the implications for sight restoration technologies","type":"publication"},{"authors":["Michael Beyeler","Geoffrey M. Boynton","Ione Fine","Ariel Rokem"],"categories":null,"content":"","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"2d6cce377cc9ed496868935f2dbb3ea4","permalink":"https://bionicvisionlab.org/publication/2017-pulse2percept/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/publication/2017-pulse2percept/","section":"publication","summary":"*pulse2percept* is an open-source Python simulation framework used to predict the perceptual experience of retinal prosthesis patients across a wide range of implant configurations.","tags":["neuroengineering","retinal implants","open-source","data science","computational models","retinitis pigmentosa","biomedical engineering","Python","parallel programming"],"title":"pulse2percept: A Python-based simulation framework for bionic vision","type":"publication"},{"authors":["Michael Beyeler","Nikil Dutt","Jeffrey L. Krichmar"],"categories":null,"content":"","date":1470009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470009600,"objectID":"7bde0b15775f3061c93cf9d26d8a722b","permalink":"https://bionicvisionlab.org/publication/2016-sparse-decomposition-model/","publishdate":"2016-08-01T00:00:00Z","relpermalink":"/publication/2016-sparse-decomposition-model/","section":"publication","summary":"Using a dimensionality reduction technique known as non-negative matrix factorization, we found that a variety of medial superior temporal (MSTd) neural response properties could be derived from MT-like input features. The responses that emerge from this technique, such as 3D translation and rotation selectivity, spiral tuning, and heading selectivity, can account for a number of empirical results. These findings (1) provide a further step toward a scientific understanding of the often nonintuitive response properties of MSTd neurons; (2) suggest that response properties, such as complex motion tuning and heading selectivity, might simply be a byproduct of MSTd neurons performing dimensionality reduction on their inputs; and (3) imply that motion perception in the cortex is consistent with ideas from the efficient-coding and free-energy principles.","tags":["computational models","visual motion perception","MSTd","optic flow","nonnegative matrix factorization"],"title":"3D visual response properties of MSTd emerge from an efficient, sparse population code","type":"publication"},{"authors":["Michael Beyeler","Nicolas Oros","Nikil Dutt","Jeffrey L. Krichmar"],"categories":null,"content":"","date":1448928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448928000,"objectID":"fa66b3464f53a69c81e83355d550df5d","permalink":"https://bionicvisionlab.org/publication/2015-gpu-visually-guided-robot-navigation/","publishdate":"2015-12-01T00:00:00Z","relpermalink":"/publication/2015-gpu-visually-guided-robot-navigation/","section":"publication","summary":"We present a cortical neural network model for visually guided navigation that has been embodied on a physical robot exploring a real-world environment. The model includes a rate based motion energy model for area V1, and a spiking neural network model for cortical area MT. The model generates a cortical representation of optic flow, determines the position of objects based on motion discontinuities, and combines these signals with the representation of a goal location to produce motor commands that successfully steer the robot around obstacles toward the goal. This study demonstrates how neural signals in a model of cortical area MT might provide sufficient motion information to steer a physical robot on human-like paths around obstacles in a real-world environment.","tags":["computational models","spiking neural networks","CARLsim","GPU","parallel programming","visual motion perception","pattern motion selectivity","MT","visually guided navigation","robot navigation"],"title":"A GPU-accelerated cortical neural network model for visually guided robot navigation","type":"publication"},{"authors":["Michael Beyeler","Kristofor D. Carlson","Ting-Shou Chou","Nikil Dutt","Jeffrey L. Krichmar"],"categories":null,"content":"","date":1436659200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1436659200,"objectID":"924b641054ea0e69270600c5c06b1975","permalink":"https://bionicvisionlab.org/publication/2015-carlsim3/","publishdate":"2015-07-12T00:00:00Z","relpermalink":"/publication/2015-carlsim3/","section":"publication","summary":"We have developed CARLsim 3, a user-friendly, GPU-accelerated SNN library written in C/C++ that is capable of simulating biologically detailed neural models. The present release of CARLsim provides a number of improvements over our prior SNN library to allow the user to easily analyze simulation data, explore synaptic plasticity rules, and automate parameter tuning. In the present paper, we provide examples and performance benchmarks highlighting the library's features.","tags":["computational models","spiking neural networks","CARLsim","GPU","parallel programming","C++"],"title":"CARLsim 3: A user-friendly and highly optimized library for the creation of neurobiologically detailed spiking neural networks","type":"publication"},{"authors":["Michael Beyeler","Florian Mirus","Alexander Verl"],"categories":null,"content":"","date":1401580800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1401580800,"objectID":"f64e29214acef64cd605d0dee5f7df1e","permalink":"https://bionicvisionlab.org/publication/2014-vision-road-lane-detection/","publishdate":"2014-06-01T00:00:00Z","relpermalink":"/publication/2014-vision-road-lane-detection/","section":"publication","summary":"This paper presents an integrative approach to ego-lane detection that aims to be as simple as possible to enable real-time computation while being able to adapt to a variety of urban and rural traffic scenarios. The approach at hand combines and extends a road segmentation method in an illumination-invariant color image, lane markings detection using a ridge operator, and road geometry estimation using RANdom SAmple Consensus (RANSAC). The power and robustness of this algorithm has been demonstrated in a car simulation system as well as in the challenging KITTI data base of real-world urban traffic scenarios.","tags":["computational models","computer vision","driver information systems","intelligent transportation systems","image segmentation","object detection","road traffic","KITTI"],"title":"Vision-based robust road lane detection in urban environments","type":"publication"},{"authors":["Michael Beyeler","Micah Richert","Nikil Dutt","Jeffrey L. Krichmar"],"categories":null,"content":"","date":1391558400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1391558400,"objectID":"96b515fcb79c860869313bf9febe2c91","permalink":"https://bionicvisionlab.org/publication/2014-snn-pattern-motion/","publishdate":"2014-01-20T00:00:00Z","relpermalink":"/publication/2014-snn-pattern-motion/","section":"publication","summary":"We present a two-stage model of visual area MT that we believe to be the first large-scale spiking network to demonstrate pattern direction selectivity. In this model, component-direction-selective (CDS) cells in MT linearly combine inputs from V1 cells that have spatiotemporal receptive fields according to the motion energy model of Simoncelli and Heeger. Pattern-direction-selective (PDS) cells in MT are constructed by pooling over MT CDS cells with a wide range of preferred directions. Responses of our model neurons are comparable to electrophysiological results for grating and plaid stimuli as well as speed tuning.","tags":["spiking neural networks","visual motion perception","pattern motion selectivity","MT","parallel programming","GPU","CARLsim"],"title":"Efficient spiking neural network model of pattern motion selectivity in visual cortex","type":"publication"},{"authors":["Kristofor D. Carlson","Michael Beyeler","Nikil Dutt","Jeffrey L. Krichmar"],"categories":null,"content":"","date":1390176000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1390176000,"objectID":"ae0ad4a16dae311c5e5d007164a39eee","permalink":"https://bionicvisionlab.org/publication/2014-gpgpu-accelerated-simulation-parameter-tuning/","publishdate":"2014-01-20T00:00:00Z","relpermalink":"/publication/2014-gpgpu-accelerated-simulation-parameter-tuning/","section":"publication","summary":"We describe a simulation environment that can be used to design, construct, and run spiking neural networks (SNNs) quickly and efficiently using graphics processing units (GPUs). We then explain how the design of the simulation environment utilizes the parallel processing power of GPUs to simulate large-scale SNNs and describe recent modeling experiments performed using the simulator. Finally, we present an automated parameter tuning framework that utilizes the simulation environment and evolutionary algorithms to tune SNNs.","tags":["neuromorphic engineering","spiking neural networks","evolutionary algorithms","parallel programming","GPU"],"title":"GPGPU accelerated simulation and parameter tuning for neuromorphic applications","type":"publication"},{"authors":["Michael Beyeler","Nikil Dutt","Jeffrey L. Krichmar"],"categories":null,"content":"","date":1385856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1385856000,"objectID":"4b3672d3c8372629471a2a3248359d59","permalink":"https://bionicvisionlab.org/publication/2013-categorization-mnist-stdp/","publishdate":"2013-12-01T00:00:00Z","relpermalink":"/publication/2013-categorization-mnist-stdp/","section":"publication","summary":"We present a large-scale model of a hierarchical spiking neural network (SNN) that integrates a low-level memory encoding mechanism with a higher-level decision process to perform a visual classification task in real-time. The model consists of Izhikevich neurons and conductance-based synapses for realistic approximation of neuronal dynamics, a spike-timing-dependent plasticity (STDP) synaptic learning rule with additional synaptic dynamics for memory encoding, and an accumulator model for memory retrieval and categorization. The full network, which comprised 71,026 neurons and approximately 133 million synapses, ran in real-time on a single off-the-shelf graphics processing unit (GPU). The network achieved 92% correct classifications on MNIST in 100 rounds of random sub-sampling, which is comparable to other SNN approaches and provides a conservative and reliable performance metric. Additionally, the model correctly predicted reaction times from psychophysical experiments. Because of the scalability of the approach and its neurobiological fidelity, the current model can be extended to an efficient neuromorphic implementation that supports more generalized object recognition and decision-making architectures found in the brain.","tags":["computational models","spiking neural networks","synaptic plasticity","parallel programming","GPU","MNIST"],"title":"Categorization and decision-making in a neurobiologically plausible spiking network using a STDP-like plasticity rule","type":"publication"},{"authors":["Michael Beyeler","Fabio Stefanini","Henning Proske","Giovanni Galizia","Elisabetta Chicca"],"categories":null,"content":"","date":1288569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1288569600,"objectID":"bc1e436831b5c9690ee42ff2b36e90a3","permalink":"https://bionicvisionlab.org/publication/2010-exploring-olfactory-networks/","publishdate":"2010-11-01T00:00:00Z","relpermalink":"/publication/2010-exploring-olfactory-networks/","section":"publication","summary":"Olfactory stimuli are represented in a high-dimensional space by neural networks of the olfactory system. While a number of studies have illustrated the importance of inhibitory networks within the olfactory bulb or the antennal lobe for the shaping and processing of olfactory information, it is not clear how exactly these inhibitory networks are organized to provide filtering and contrast enhancement capabilities. In this work the aim is to study the topology of the proposed networks by using software simulations and hardware implementation. While we can study the dependence of the activity on each parameter of the theoretical models with the simulations, it is important to understand whether the models can be used in robotic applications for real-time odor recognition. We present the results of a linear simulation, a spiking simulation with I\u0026F neurons and a real-time hardware emulation using neuromorphic VLSI chips.","tags":["neuromorphic engineering","olfaction"],"title":"Exploring olfactory sensory networks: Simulations and hardware emulation","type":"publication"}]