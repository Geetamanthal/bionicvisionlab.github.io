[{"categories":null,"content":"Anvitha Akkaraju is an undergraduate student in the Department of Psychological and Brain Sciences at the University of California, Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c5af182f990d49f86f3deb07078e8356","people":["akkaraju_anvitha"],"permalink":"https://bionicvisionlab.org/people/akkaraju_anvitha/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/akkaraju_anvitha/","section":"people","summary":"Anvitha Akkaraju is an undergraduate student in the Department of Psychological and Brain Sciences at the University of California, Santa Barbara.","title":"Anvitha Akkaraju","type":"people"},{"categories":null,"content":"Andrea Anez is an undergraduate student in Computer Engineering at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"36aae86b6ffa18ec3318e8424b2c4634","people":["anez_andrea"],"permalink":"https://bionicvisionlab.org/people/anez_andrea/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/anez_andrea/","section":"people","summary":"Andrea Anez is an undergraduate student in Computer Engineering at UC Santa Barbara.","title":"Andrea Anez","type":"people"},{"categories":null,"content":"Michael Beyeler directs the Bionic Vision Lab at UC Santa Barbara.\nHe received a PhD in Computer Science from UC Irvine as well as a BS in Electrical Engineering and a MS in Biomedical Engineering from ETH Zurich, Switzerland. Prior to joining UCSB, he completed a postdoctoral fellowship in the labs of Ione Fine (Psychology, Institute for Neuroengineering) and Ariel Rokem (eScience Institute) at the University of Washington, where he developed computational models of bionic vision.\nHe is Associate Director of the UCSB Center for Virtual Environments and Behavior (ReCVEB) and recipient of the National Institutes of Health (NIH) Pathway to Independence Award.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9b65f6e0cdcdd6af799cdb43ac4127dc","people":["beyeler_michael"],"permalink":"https://bionicvisionlab.org/people/beyeler_michael/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/beyeler_michael/","section":"people","summary":"Michael Beyeler directs the Bionic Vision Lab at UC Santa Barbara.\nHe received a PhD in Computer Science from UC Irvine as well as a BS in Electrical Engineering and a MS in Biomedical Engineering from ETH Zurich, Switzerland. Prior to joining UCSB, he completed a postdoctoral fellowship in the labs of Ione Fine (Psychology, Institute for Neuroengineering) and Ariel Rokem (eScience Institute) at the University of Washington, where he developed computational models of bionic vision.","title":"Michael Beyeler","type":"people"},{"categories":null,"content":"Tanya Bhatia is an undergraduate research assistant pursuing a degree in biopsychology. She is interested in better understanding and improving the perceptual experience of sight recovery patients and the clinical applications of computational neuroscience.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e491fe74ed0afc731854c9e3938782af","people":["bhatia_tanya"],"permalink":"https://bionicvisionlab.org/people/bhatia_tanya/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/bhatia_tanya/","section":"people","summary":"Tanya Bhatia is an undergraduate research assistant pursuing a degree in biopsychology. She is interested in better understanding and improving the perceptual experience of sight recovery patients and the clinical applications of computational neuroscience.","title":"Tanya Bhatia","type":"people"},{"categories":null,"content":"Harshita Gangaswamy is currently a second-year undergraduate student pursuing a Computer Engineering degree at UC Santa Barbara. She is interested in deep learning and computational neuroscience.\nWhen she is not studying and doing research, she enjoys reading novels and watching TV shows with her roommates and friends. She has also been volunteering to teach kids through the Society of Women Engineers.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"81655537f54e185163d76eaa9966c64b","people":["gangaswamy_harshita"],"permalink":"https://bionicvisionlab.org/people/gangaswamy_harshita/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/gangaswamy_harshita/","section":"people","summary":"Harshita Gangaswamy is currently a second-year undergraduate student pursuing a Computer Engineering degree at UC Santa Barbara. She is interested in deep learning and computational neuroscience.\nWhen she is not studying and doing research, she enjoys reading novels and watching TV shows with her roommates and friends. She has also been volunteering to teach kids through the Society of Women Engineers.","title":"Harshita Gangaswamy","type":"people"},{"categories":null,"content":"Jacob Granley is a PhD student in the Department of Computer Science.\nPrior to joining UCSB, he received his Masters and Bachelors in Computer Science from Colorado School of Mines. He is pursuing his PhD under Dr. Beyeler as part of the Bionic Vision lab, where he hopes to use Computer Science and Machine Learning methods to help improve artificial vision technologies with the ultimate goal of restoring sight to the blind.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2b70b8d79cd7bf947cd51020510152a3","people":["granley_jacob"],"permalink":"https://bionicvisionlab.org/people/granley_jacob/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/granley_jacob/","section":"people","summary":"Jacob Granley is a PhD student in the Department of Computer Science.\nPrior to joining UCSB, he received his Masters and Bachelors in Computer Science from Colorado School of Mines. He is pursuing his PhD under Dr. Beyeler as part of the Bionic Vision lab, where he hopes to use Computer Science and Machine Learning methods to help improve artificial vision technologies with the ultimate goal of restoring sight to the blind.","title":"Jacob Granley","type":"people"},{"categories":null,"content":"Yuchen Hou is a third-year undergraduate student at UC Santa Barbara. She is majoring in Psychological \u0026amp; Brain Sciences. She is interested in human-computer interaction and plans to pursue a master\u0026rsquo;s degree in a related field.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e3745716f7ad68c766108f2e2cbeefef","people":["hou_yuchen"],"permalink":"https://bionicvisionlab.org/people/hou_yuchen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/hou_yuchen/","section":"people","summary":"Yuchen Hou is a third-year undergraduate student at UC Santa Barbara. She is majoring in Psychological \u0026amp; Brain Sciences. She is interested in human-computer interaction and plans to pursue a master\u0026rsquo;s degree in a related field.","title":"Yuchen Hou","type":"people"},{"categories":null,"content":"Byron is a PhD student in the Department of Psychological \u0026amp; Brain Sciences. He was born and raised in St. Louis, Missouri. He moved to New York City to study psychology, where he received a BA in Psychology from St. John’s University (2015) and then a MA in Behavioral Neuroscience from Queens College (2017). Byron worked as a Research Operations Manager at a start-up company that develops assistive products for blind and low vision individuals (2017 - 2020).\nByron\u0026rsquo;s main research interest is studying how image processing and psychophysics can be used to understand how low vision conditions affect visual tasks. Specifically, how combining computational models with simulated low vision impairment conditions can help inform and enhance individualized vision capabilities. Byron is supervised by Dr. Michael Beyeler in the Bionic Vision Lab and Dr. Miguel Eckstein in the Vision and Image Understanding Lab.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"226dccd548b210ce20689586bc7b8aba","people":["johnson_byron"],"permalink":"https://bionicvisionlab.org/people/johnson_byron/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/johnson_byron/","section":"people","summary":"Byron is a PhD student in the Department of Psychological \u0026amp; Brain Sciences. He was born and raised in St. Louis, Missouri. He moved to New York City to study psychology, where he received a BA in Psychology from St. John’s University (2015) and then a MA in Behavioral Neuroscience from Queens College (2017). Byron worked as a Research Operations Manager at a start-up company that develops assistive products for blind and low vision individuals (2017 - 2020).","title":"Byron Johnson","type":"people"},{"categories":null,"content":"Justin Kasowksi transferred to UC Santa Barbara in 2016 after receiving associates degrees in Biological Sciences and Chemistry from Santa Barbara City College. In 2018, he graduated UCSB with a degree in Molecular, Cellular, and Developmental Biology.\nHe is pursuing his PhD under Dr. Michael Beyeler in the Bionic Vision Lab, where he utilizes virtual reality and computer vision to model the perceptual experience of retinal prosthesis patients.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"25e494b70e3d83523af0ee2774cf00aa","people":["kasowski_justin"],"permalink":"https://bionicvisionlab.org/people/kasowski_justin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/kasowski_justin/","section":"people","summary":"Justin Kasowksi transferred to UC Santa Barbara in 2016 after receiving associates degrees in Biological Sciences and Chemistry from Santa Barbara City College. In 2018, he graduated UCSB with a degree in Molecular, Cellular, and Developmental Biology.\nHe is pursuing his PhD under Dr. Michael Beyeler in the Bionic Vision Lab, where he utilizes virtual reality and computer vision to model the perceptual experience of retinal prosthesis patients.","title":"Justin Kasowski","type":"people"},{"categories":null,"content":"Ananth Mahes is an undergraduate student pursuing a degree in Biopsychology at the University of California, Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c5bbeb3a42a7419d3b0df805a71922b2","people":["mahes_ananth"],"permalink":"https://bionicvisionlab.org/people/mahes_ananth/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/mahes_ananth/","section":"people","summary":"Ananth Mahes is an undergraduate student pursuing a degree in Biopsychology at the University of California, Santa Barbara.","title":"Ananth Mahes","type":"people"},{"categories":null,"content":"Sahil Naik is currently a third-year undergraduate student pursuing a Computer Engineering degree at UC Santa Barbara. He is currently interested in Computational Neuroscience and Artificial Intelligence but hopes to delve more into deep learning in the future. He also really loves the beach and beach games like die and spikeball.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"557653db966b2d3531471d2469543fa0","people":["naik_sahil"],"permalink":"https://bionicvisionlab.org/people/naik_sahil/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/naik_sahil/","section":"people","summary":"Sahil Naik is currently a third-year undergraduate student pursuing a Computer Engineering degree at UC Santa Barbara. He is currently interested in Computational Neuroscience and Artificial Intelligence but hopes to delve more into deep learning in the future. He also really loves the beach and beach games like die and spikeball.","title":"Sahil Naik","type":"people"},{"categories":null,"content":"Ryan Neydavood is an undergraduate student at UC Santa Barbara, and is a Psychology \u0026amp; Brain Sciences Major. Ryan is interested in VR, neurophysiology, and advancing the field of bionic vision to help cure blindness.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"07bcf61e83804b1777afd8d80daa4116","people":["neydavood_ryan"],"permalink":"https://bionicvisionlab.org/people/neydavood_ryan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/neydavood_ryan/","section":"people","summary":"Ryan Neydavood is an undergraduate student at UC Santa Barbara, and is a Psychology \u0026amp; Brain Sciences Major. Ryan is interested in VR, neurophysiology, and advancing the field of bionic vision to help cure blindness.","title":"Ryan Neydavood","type":"people"},{"categories":null,"content":"Bill Nguyen is an undergraduate student in the Departments of Psychological \u0026amp; Brain Sciences (PBS) and Mathematics at UC Santa Barbara. He is interested in the exciting potential of neural prostheses, both on a technological and clinical level.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"88921ab62b48dba707e97e967eaf728b","people":["nguyen_bill"],"permalink":"https://bionicvisionlab.org/people/nguyen_bill/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/nguyen_bill/","section":"people","summary":"Bill Nguyen is an undergraduate student in the Departments of Psychological \u0026amp; Brain Sciences (PBS) and Mathematics at UC Santa Barbara. He is interested in the exciting potential of neural prostheses, both on a technological and clinical level.","title":"Bill Nguyen","type":"people"},{"categories":null,"content":"Alex Rasla is currently a first-year graduate student in the B.S/M.S. program pursuing a Computer Science degree at UC Santa Barbara. He is interested in Machine Learning, Computer Vision, AR/VR, and autonomous systems.\nIn his free time, Alex enjoys playing the piano or guitar, and producing music. Some of his other hobbies include hanging out at the beach, reading books, and playing sports. Once he graduates, Alex wants to work for a company that makes the world a better place.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6070452bd4da4b5fcb8adc841079aee1","people":["rasla_alex"],"permalink":"https://bionicvisionlab.org/people/rasla_alex/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/rasla_alex/","section":"people","summary":"Alex Rasla is currently a first-year graduate student in the B.S/M.S. program pursuing a Computer Science degree at UC Santa Barbara. He is interested in Machine Learning, Computer Vision, AR/VR, and autonomous systems.\nIn his free time, Alex enjoys playing the piano or guitar, and producing music. Some of his other hobbies include hanging out at the beach, reading books, and playing sports. Once he graduates, Alex wants to work for a company that makes the world a better place.","title":"Alex Rasla","type":"people"},{"categories":null,"content":"Madori Spiker is a MS student in Computer Science at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"16a892356347222eb5ddec17b1eca141","people":["spiker_madori"],"permalink":"https://bionicvisionlab.org/people/spiker_madori/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/spiker_madori/","section":"people","summary":"Madori Spiker is a MS student in Computer Science at UC Santa Barbara.","title":"Madori Spiker","type":"people"},{"categories":null,"content":"Gita Supramaniam is currently a second-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara.\nIn her free time, she enjoys reading and going on walks.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"06ff86945e97b58a6925161ae5f82ff8","people":["supramaniam_gita"],"permalink":"https://bionicvisionlab.org/people/supramaniam_gita/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/supramaniam_gita/","section":"people","summary":"Gita Supramaniam is currently a second-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara.\nIn her free time, she enjoys reading and going on walks.","title":"Gita Supramaniam","type":"people"},{"categories":null,"content":"Archita Tharanipathy is currently a third-year undergraduate student pursuing a Biochemistry and Molecular Biology degree at the University of California, Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e5c7bdda5b82dd1d2724bb186db9f152","people":["tharanipathy_archita"],"permalink":"https://bionicvisionlab.org/people/tharanipathy_archita/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/tharanipathy_archita/","section":"people","summary":"Archita Tharanipathy is currently a third-year undergraduate student pursuing a Biochemistry and Molecular Biology degree at the University of California, Santa Barbara.","title":"Archita Tharanipathy","type":"people"},{"categories":null,"content":"Apurv Varshney is currently a first-year graduate student pursuing a Master\u0026rsquo;s in Computer Science degree at UC Santa Barbara. He is interested in improving Bionic Vision using Computer vision and human computer interaction (HCI) techniques. In his free time he enjoys hiking and playing Tennis.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"283fe3910514662d9abab07376970c6f","people":["varshney_apurv"],"permalink":"https://bionicvisionlab.org/people/varshney_apurv/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/varshney_apurv/","section":"people","summary":"Apurv Varshney is currently a first-year graduate student pursuing a Master\u0026rsquo;s in Computer Science degree at UC Santa Barbara. He is interested in improving Bionic Vision using Computer vision and human computer interaction (HCI) techniques. In his free time he enjoys hiking and playing Tennis.","title":"Apurv Varshney","type":"people"},{"categories":null,"content":"Francie Wei is currently a fourth-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. She is interested in machine learning behind artificial vision.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"58bc915d1d9d4f5a8a3a730dbb259dc1","people":["wei_francie"],"permalink":"https://bionicvisionlab.org/people/wei_francie/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/wei_francie/","section":"people","summary":"Francie Wei is currently a fourth-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. She is interested in machine learning behind artificial vision.","title":"Francie Wei","type":"people"},{"categories":null,"content":"Aiwen Xu is a PhD student in Computer Science. Prior to UC Santa Barbara, she received a BS in Computer Science and a BS in Mathematics from New York University Shanghai. She hopes to utilize mathematical modeling and machine learning techniques to improve bionic vision.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8f8cb324f0e2fc7e16448789c3667a8d","people":["xu_aiwen"],"permalink":"https://bionicvisionlab.org/people/xu_aiwen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/xu_aiwen/","section":"people","summary":"Aiwen Xu is a PhD student in Computer Science. Prior to UC Santa Barbara, she received a BS in Computer Science and a BS in Mathematics from New York University Shanghai. She hopes to utilize mathematical modeling and machine learning techniques to improve bionic vision.","title":"Aiwen Xu","type":"people"},{"categories":[],"content":"Prof. Beyeler was part of the Giz Asks series, where the focused turned to the prospect of using brain-machine interface technology to directly write in information to the brain.\nRead the full interview here.\n","date":1632155340,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632155353,"objectID":"97e77cd152658cef8ec13fdd329eb163","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/post/2021-09-giz-asks/","publishdate":"2021-09-20T09:29:00-07:00","relpermalink":"/post/2021-09-giz-asks/","section":"post","summary":"Prof. Beyeler was featured in a Giz Asks article about the prospect of using brain-machine interfaces to directly write in information to the brain.","title":"Will it ever be possible to upload information to my brain?","type":"post"},{"categories":null,"content":"","date":1631232000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631232000,"objectID":"bd0e96fe8780217f5653eb89d9b142ad","people":["Justin Kasowski","Byron Johnson","Ryan Neydavood","Anvitha Akkaraju","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-xr-visual-accessibility/","publishdate":"2021-09-10T00:00:00Z","relpermalink":"/publications/2021-xr-visual-accessibility/","section":"publications","summary":"We present a systematic literature review of 216 publications from 109 different venues assessing the potential of XR technology to serve as not just a visual accessibility aid but also as a tool to study perception and behavior in people with low vision and blind people whose vision was restored with a neuroprosthesis.","title":"Furthering visual accessibility with extended reality (XR): a systematic review","type":"publications"},{"categories":null,"content":"What would the world look like with a bionic eye?\nThis graduate course will introduce students to the multidisciplinary field of bionic vision viewed through the lens of computer science, neuroscience, and human-computer interaction.\nThe course will conclude with a programming project (teams of ≤ 3, any language/environment ok) in lieu of a final exam, giving students an opportunity to gain hands-on experience of working on open research problems using methods and tools best suited to their scientific background.\n         Instructor Michael Beyeler (first initial last name at ucsb dot edu)   Class F21, Tue/Thu 9:00 \u0026ndash; 10:50 am, Phelps 3526   Office Hours Tue 2\u0026ndash;4 pm Zoom (schedule a meeting)    \rChangelog:\r 2021-09-27: Updated office hours and assigned reading for Week 1 2021-09-15: Posted initial schedule  \rCourse Objectives The course will give an overview of current bionic eye technology designed to restore vision to people living with incurable blindness. By the end of the course, you should be able to:\n identify various types of bionic eye technologies, their differences and similarities explain how the retina and visual cortex support our sense of seeing apply common computer vision \u0026amp; machine learning techniques for stimulus encoding give a nuanced review of the HCI \u0026amp; ethics issues associated with implantable neurotechnology demonstrate your hands-on experience of working on open problems in the field  The course is targeted to a diverse audience spanning computer science (computer vision, human factors, deep learning) to psychology (vision, psychophysics) and brain sciences (computational neuroscience, neuroengineering).\nPrerequisites  There are no official prerequisites for this course. The instructor will do his best to make the course content self-contained, including a crash course in neuroscience \u0026amp; computational vision. However, homeworks and final projects will require programming. Homeworks will be based around pulse2percept, a Python-based simulation framework for bionic vision. Any suitable programming language/framework is ok for the final project.  FAQ  Will classes be in person? Yes, and you are strongly encouraged to attend. What about office hours? I will offer both in-person and virtual office hours. Do instructors and students need to wear a mask in class? Yes. There will be no exceptions to this policy. Sure, it\u0026rsquo;ll be a little weird at first, but I\u0026rsquo;m sure we\u0026rsquo;ll all adjust pretty quickly. What if I can\u0026rsquo;t make a lecture? Send me a quick email before the lecture. You don\u0026rsquo;t need a reason for your first 3 absences. I will do my best to record the lectures and upload them to GauchoCast for those who cannot make a lecture, but I am unable to make any remote accommodations beyond that. What if I\u0026rsquo;m sick or need to quarantine or isolate? Now more important than ever, do not come in if you feel under the weather. Email me, then follow UCSB testing \u0026amp; quarantine protocol. What if the instructor needs to quarantine? In this case we will temporarily shift to remote instruction. What if my question isn\u0026rsquo;t answered here? I\u0026rsquo;m happy to answer your question via email.  Schedule Note: This schedule is subject to slight change over the course of the quarter.\n\r\rWk\rDate\rReading\rTopics\rAction\rHWout\rHWdue\rQuiz\r\r\r\r\r0\rThu\rSep 23\r\rR1\r\r\r\rIntroduction: Class requirements \u0026 policies\rBionic vision: then \u0026 now\r\r\r\r\r\r\r\r\r\r1\rTue\rSep 28\rR2, R3\r\r\rSight restoration: approaches \u0026 challenges\rFoundations of vision\r \r\rHW1\r\r\r\r\rThu\rSep 30\r\r\r\rComputational neuroscience\rIntroduction to Google Colab \u0026 Python\r\r Quiz 1 (Q1) due by Sun, Oct 3, 11:59 pm.\r\r\r\rA1\r\r\rQ1\r\r\r2\rTue\rOct 5\r\r\rGuest lecture by Aiwen Xu\r\rRetina in health \u0026 disease\r\r\r\r\r\r\r\r\rThu\rOct 7\r\r\r\r\rRetinal prostheses: approaches \u0026 challenges\rArgus II, PRIMA, BVT-44\r\r Homework 1 (HW1) due by Sun, Oct 10, 11:59 pm.\r\r\r\r\r\rHW1\r\r\r\r3\rTue\rOct 12\r\r\r\rComputational models of bionic vision\rPhosphene models: scoreboard \u0026 axon map model\r\r\r\r\r\r\r\r\rThu\rOct 14\r\r\r\rIntroduction to pulse2percept in Python\rProject ideas: Discussion \u0026 brainstorming\r\r Quiz 2 (Q2) due by Sun, Oct 17, 11:59 pm.\r\r\r\rA2\rHW2\r\rQ2\r\r\r4\rTue\rOct 19\r\r\r\rThe role of machine learning in bionic vision\rAdvanced stimulation strategies\r\r\r\r\r\r\r\r\rThu\rOct 21\r\r\r\rOptimizing electrical stimulation in an artificial retina\r\r Homework 2 (HW2) due by Sun, Oct 24, 11:59 pm.\r\r\r\r\r\rHW2\r\r\r\r5\rTue\rOct 26\r\r\r\rBionic Vision XR\r\r\r\r\r\r\r\r\rThu\rOct 28\r\r\rTeams present their project proposal \rTeam \u0026 project description (TPD) due by Sun, Oct 31, 11:59 pm.\r\r  \r\rTPD\r\r\r\r6\rTue\rNov 2\r\r\r\rThe role of image processing in bionic vision\rScene representation \u0026 simplification\r\r\r\r\r\r\r\r\rThu\rNov 4\r\r\r\rSemantic segmentation for bionic vision\r\r Quiz 3 (Q3) due by Sun, Nov 7, 11:59 pm.\r\r\r\r\r\r\rQ3\r\r\r7\rTue\rNov 9\r\r\r\rCortical prostheses: approaches \u0026 challenges\rPhosphene models for cortical prostheses\r\r\r\r\r\r\r\rThu\rNov 11\r\r\rVeterans' Day\r\r\r\r\r\r\r\r8\rTue\rNov 16\r\r\r\rLearning to see again with a bionic eye\rVisual rehabilitation\r\r\r\r\r\r\r\r\rThu\rNov 18\r\r\rGuest Visit: Jason Esterhuizen, ORION implantee \r Quiz 4 (Q4) due by Sun, Nov 21, 11:59 pm.\r\r\r\r\rA3\r\r\r\r\rQ4\r\r\r9\rTue\rNov 23\r\r\rTeams present project progress\r\r\r\r\r\r\rThu\rNov 25\r\r\r\rThanksgiving Day\r\r\r\r\r\r\r\r10\rTue\rNov 30\r\r\r\r\rOutlook: Future of bionic vision\rAlternatives to brain-computer interfaces\r\r\r\r\r\r\r\r\rThu\rDec 2\r\r\r\r\rQuarter review\r\r\rProject report (PR) \u0026amp; source code (SC) due Sun, Dec 5, 11:59 pm.\r\r\r\r\rA4\r\r\rPR\u0026amp;SC\r\r\r11\rTue\rDec 7\r\rTeams make their final project presentations\r\r\r\r\r\r\r\rCourse Requirements \u0026amp; Grading Your final grade will be determined as follows:\n 20% Homework assignments:  10% Homework 1 10% Homework 2   30% \u0026ldquo;Check Your Knowledge\u0026rdquo; quizzes  10% per quiz Lowest-scoring quiz will be dropped   50% Final project implementation, documentation, and presentation  5% Project proposal presentation (1 slide) 5% Project progress presentation (2 slides: what have you done, what\u0026rsquo;s left to do) 20% Project final presentation 20% Project final report (+5% extra credit if project shows promise of turning into a publication)    Lateness Policy All assignments are due at 11:59:59 pm on the scheduled due date, typically a Sunday (timestamp of the online submission system).\n Each student will be allowed 3 \u0026ldquo;late days\u0026rdquo; over the course of the quarter for which lateness will not be penalized. Late days cannot be applied to project deadlines. Late days may be applied to the quizzes and homework assignments: Anything turned in between 12:00:00 am and 11:59:59 pm the next day is one day late; every day thereafter that an assignment is late, including weekends and holidays, counts as an additional late day. No late work will be accepted after the deadline if you have used up all your late days. If you\u0026rsquo;re not done on time, you should turn in what you have to receive partial credit. No exceptions will be made for the final project report.  Please make sure you understand this policy.\n\u0026ldquo;Check Your Knowledge\u0026rdquo; Quizzes We will have 4 GauchoSpace quizzes over the quarter that test your theoretical/conceptual knowledge of the course content (this includes lectures and assigned reading materials).\nThe following rules apply:\n Quizzes must be completed by Sunday 11:59 pm of the respective week (lateness policy applies) You have 30 mins per attempt A quiz can be taken twice. If you decide to take the quiz again, only your second attempt will be counted (that is, the score from your first attempt will be dropped, this is called \u0026ldquo;grading method: last attempt\u0026rdquo; on GauchoSpace) At the end of the quarter, the lowest-scoring quiz will be dropped. (Each of the 3 highest-scoring quizzes will thus account for 10% of your grade)  Final Project In lieu of a final exam, students will conduct a programming project (team size ≤ 3). The goal of the project is to gain hands-on experience working on open research questions in bionic vision using tools and methods best suited to their scientific background.\nAll projects must address a research question and have a programming component. Students are free to use any programming language and development environment they choose. Building a project based on pulse2percept is encouraged (especially for students with relatively little programming experience) but is by no means required. Reproducing key research findings in the literature is allowed. No pure literature reviews, please.\nProjects that show promise of turning into a publication will receive extra credit.\nStudents will present their project to the rest of the class during finals week. In addition, students will submit a write-up of their project and hand in their source code (see Milestones).\nThe project will be evaluated based on the:\n originality/novelty of the idea technical strength of the work (emphasis on the research, not the programming expertise) organization, clarity, and style of the project report effort and completeness of the work (normalized by the number of team members)  Project Milestones    Date Time Deliverable due     Thu, Oct 14 9:00 am Students start forming teams and discussing project ideas in class.   Thu, Oct 28 9:00 am Teams present their project ideas in class.   Sun, Oct 31 11:59 pm Teams submit a project title and 2-3 sentence project description.   Tue, Nov 23 9:00 am Teams present their project progress in class.   Sun, Dec 5 11:59 pm Teams hand in their final project report and all source code.   Tue, Dec 7 9:00 am Teams make their final project presentations in class.    Students are encouraged to discuss ideas with the instructors, so that feedback can be incorporated early in the process.\nLate days cannot be used on these project deadlines.\nAcademic Integrity The University of California has formal policies related to academic integrity.\nAny act of academic dishonesty, such as cheating or plagiarism, will result in a University disciplinary action and an \u0026ldquo;F\u0026rdquo; in this course. In addition to academic integrity, I also expect everyone in this class to treat their fellow students and course staff with respect.\nBasic Needs If you are facing any challenges securing food or housing and believe this may affect your performance in the class, you are urged to meet with a Food Security and Calfresh Advocate who is aware of the broad variety of resources that UCSB has to offer (see their drop-in hours at food.ucsb.edu). You are also urged to contact the professor if you are comfortable doing so.\nPlease visit food.ucsb.edu for additional resources including Calfresh, the AS Food Bank, and more.\n","date":1628985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628985600,"objectID":"2dad7ab16b905e022d4e43580bb840eb","people":null,"permalink":"https://bionicvisionlab.org/teaching/2021-fall-cs291a/","publishdate":"2021-08-15T00:00:00Z","relpermalink":"/teaching/2021-fall-cs291a/","section":"teaching","summary":"This graduate course will introduce students to the multidisciplinary field of bionic vision viewed through the lens of computer science, neuroscience, and human-computer interaction.","title":"CS-291A: Bionic Vision","type":"teaching"},{"categories":null,"content":"","date":1625788800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625788800,"objectID":"1ea7bfff6a164cada4127025bca057b9","people":["Jacob Granley","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-hba-u-net/","publishdate":"2021-07-09T00:00:00Z","relpermalink":"/publications/2021-hba-u-net/","section":"publications","summary":"We propose HBA-U-Net: a U-Net backbone with hierarchical bottleneck attention to highlight retinal abnormalities that may be important for fovea and optic disc segmentation in the degenerated retina.","title":"U-Net with hierarchical bottleneck attention for landmark detection in fundus images of the degenerated retina","type":"publications"},{"categories":null,"content":"","date":1623024000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623024000,"objectID":"9a060bf8d239d3032bdf3b9c520fe632","people":["Jacob Granley","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-biphasic-axon-map/","publishdate":"2021-06-07T00:00:00Z","relpermalink":"/publications/2021-biphasic-axon-map/","section":"publications","summary":"We present a phenomenological model that predicts phosphene appearance as a function of stimulus amplitude, frequency, and pulse duration.","title":"A computational model of phosphene appearance for epiretinal prostheses","type":"publications"},{"categories":null,"content":"","date":1620086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620086400,"objectID":"ce7e87355e58295ded0c12942f667a7c","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-explainable-ai/","publishdate":"2021-05-04T00:00:00Z","relpermalink":"/publications/2021-explainable-ai/","section":"publications","summary":"We present an explainable artificiall intelligence (XAI) model fit on a large longitudinal dataset that can predict electrode deactivation in Argus II.","title":"Explainable AI for retinal prostheses: Predicting electrode deactivation from routine clinical measures","type":"publications"},{"categories":[],"content":"Over the years, cyberpunk tales and sci-fi series have featured characters with cybernetic vision—most recently Star Trek Discovery\u0026rsquo;s Lieutenant Keyla Detmer and her ocular implants. In the real world, restoring “natural” vision is still a complex puzzle, though researchers at UC Santa Barbara are developing a smart prosthesis that provides cues to the visually impaired, much like a computer vision system talks to a self-driving car.\nToday, over 10 million people worldwide are living with profound visual impairment, many due to retinal degeneration diseases. Ahead of this week\u0026rsquo;s Augmented Humans International Conference, we spoke with Dr. Michael Beyeler, Assistant Professor in Computer Science and Psychological \u0026amp; Brain Sciences at UCSB, who is forging ahead with synthetic sight trials at his Bionic Vision Lab and will be presenting a paper at the conference.\nRead the full interview here.\n","date":1614097740,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614097753,"objectID":"12d36a5e56f13526d99026da0f2d0eb9","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/post/2021-02-pcmag/","publishdate":"2021-02-23T09:29:00-07:00","relpermalink":"/post/2021-02-pcmag/","section":"post","summary":"Instead of focusing on one day restoring ‘natural’ vision, we may be better off thinking about how to create ‘practical’ and ‘useful’ artificial vision now.","title":"PCMag: Building the bionic eye... with car tech?","type":"post"},{"categories":null,"content":"","date":1613952000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613952000,"objectID":"f4d31dde088561df71570dfd3af2cf11","people":["Aiwen Xu","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-scene-simplification/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/publications/2021-scene-simplification/","section":"publications","summary":"We combined deep learning-based scene simplification strategies with a psychophysically validated computational model of the retina to generate realistic predictions of simulated prosthetic vision.","title":"Deep learning-based scene simplification for bionic vision","type":"publications"},{"categories":null,"content":"Same course as ECE 181. Not open for credit to students who have completed ECE/CMPSC 181B with a grade of C or better. ECE/CMPSC 181 is a legal repeat of ECE/CMPSC 181B.\nPrerequisites: Upper-division standing in Electrical Engineering, Computer Engineering, Computer Science, Chemical Engineering or Mechanical Engineering.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"ae5ee224e19cf700fc8876dd2c5037bf","people":null,"permalink":"https://bionicvisionlab.org/teaching/2021-winter-cs181/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/teaching/2021-winter-cs181/","section":"teaching","summary":"Overview of computer vision problems and techniques for analyzing the content of images and video. Topics include image formation, edge detection, image segmentation, pattern recognition, texture analysis, optical flow, stereo vision, shape representation and recovery techniques, issues in object recognition, and case studies of practical vision systems.","title":"CS/ECE-181: Introduction to Computer Vision","type":"teaching"},{"categories":[],"content":"Dr. Beyeler sat down with Luming Cao from SciSection\u0026rsquo;s Human and Science platform to talk about how bionic vision, as sci-fi as it sounds, is already helping to restore vision to the blind.\nThe transcript of this informal interview is now available, and a podcast will follow soon.\nRead the full interview here.\n","date":1601742540,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601742553,"objectID":"ec3c44a3dfec833dd01f282eefa9461f","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/post/2020-10-scisection/","publishdate":"2020-10-03T09:29:00-07:00","relpermalink":"/post/2020-10-scisection/","section":"post","summary":"Dr. Beyeler talks about how bionic vision, as sci-fi as it sounds, is already helping to restore vision to the blind.","title":"SciSection: Interview with Michael Beyeler","type":"post"},{"categories":null,"content":"PSY 110A is the former number of PSY 130. Students who have completed PSY110A with a C- or below may take PSY 130 as a legal repeat.\nPrerequisites: Open to Psychological \u0026amp; Brain Sciences, Biopsychology, and Interdisciplinary Studies majors only.\nWe take our ability to see for granted. It is for the most part automatic and effortless and thus might seem relatively simple. But behind the scenes our brains dedicate over a 1/4 of their machinery to analyze and interpret the light falling on our eyes. How does the brain do it?\nIn this course we will learn how the brain gives rise to our visual experience from seeing depth, color, and motion, to recognizing faces and objects. Importantly, the course illustrates an approach to study psychology and the brain combining behavioral research, neurophysiology and computational theory.\n","date":1601424000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601424000,"objectID":"42140d1938d80b337f7aa7055292a764","people":null,"permalink":"https://bionicvisionlab.org/teaching/2020-fall-psych130/","publishdate":"2020-09-30T00:00:00Z","relpermalink":"/teaching/2020-fall-psych130/","section":"teaching","summary":"An overview of theory and research into the human performance and biological processes of visual perception. Typical topics may range from the detection of simple stimuli to the identification of objects and events.","title":"PSY-130: Perception - Vision","type":"teaching"},{"categories":[],"content":"Michael Beyeler and the Bionic Vision Lab are featured heavily in the Spring Edition of UCSB\u0026rsquo;s College of Engineering Convergence Magazine:\n \u0026ldquo;There is research to try to understand the brain—how it works on a mechanistic and algorithmic level—and then there\u0026rsquo;s applying that to an engineered system that can interface with the brain,\u0026rdquo; says Michael Beyeler, an assistant professor in Computer Science and Psychological \u0026amp; Brain Sciences, in providing context for his research, which lies in the emerging interdisciplinary field of neuroengineering.\n  “Brain-computer interfaces can be used both for treating neurological and mental disorders as well as for understanding brain function,” he says. “Eventually, they should also allow us to restore vision to the blind.”\n Read the full article here.\n","date":1588350540,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588350553,"objectID":"e67f6c32303141447581b0c8bdb0f443","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/post/2020-05-convergence/","publishdate":"2020-05-01T09:29:00-07:00","relpermalink":"/post/2020-05-convergence/","section":"post","summary":"Bionic Vision Lab featured in UCSB College of Engineering's Convergence Magazine.","title":"UCSB Convergence: Reverse engineering the brain","type":"post"},{"categories":null,"content":"What would the world look like with a bionic eye?\nThis graduate course will introduce students to the multidisciplinary field of bionic vision, with an emphasis on both the computer science and neuroscience of the field.\nThe course will conclude with a programming project (teams of ≤ 3, any language/environment ok) in lieu of a final exam, giving students an opportunity to gain hands-on experience of working on open research problems using methods and tools best suited to their scientific background.\n         Instructor Michael Beyeler (first initial last name at ucsb dot edu)   Class WQ 2020, Tue/Thu 9:00 \u0026ndash; 10:50 am, Phelps 3526   Office Hours Tue 4:00 \u0026ndash; 5:00 pm or by appointment, Psych East 3822    This website and the Piazza Forum will be used as centers for communication. Homework submission will occur through GauchoSpace. Make sure you are enrolled! (Come to class to get an add code.)\nTable of Contents\r Course Objectives Prerequisites Schedule Course Requirements \u0026amp; Grading Lateness Policy Final Project  Project Milestones Project Presentation Project Report   Academic Integrity Basic Needs  \rCourse Objectives The course will give an overview of current bionic eye technology designed to restore vision to people living with incurable blindness. By the end of the course, you should be able to:\n Identify various types of bionic eye technologies, their differences and similarities Have a basic understanding of the neuroscience of the human visual system Be familiar with common preprocessing, encoding, and electrical stimulation methods Understand the limitations of current bionic eye technologies Have hands-on experience of working on open problems in the field  The course is targeted to a diverse audience spanning from computer science (human factors, neural networks, computer vision) to psychology (vision, psychophysics) and brain sciences (computational neuroscience, neuroengineering).\nPrerequisites  There are no official prerequisites for this course. The instructor will do his best to make the course content self-contained. However, prior programming experience (e.g., Python, Matlab, C++) will be highly beneficial as Homework 2 (HW2) and the final project require programming. Students will be introduced to pulse2percept, a Python-based simulation framework for bionic vision, which will form the basis for HW2 and (optionally) the final project.  Schedule Import calendar:  Note: This schedule is subject to change over the course of the quarter.\n\r\rWk\rDate\rReading\rTopics\rAction\rHW out\rHW due\r\r\r\r\r1\rTue\rJan 7\r\r\r\rIntroduction: Class requirements, policies\rBionic vision: then \u0026amp; now\r\r\r\r\r\r\r\rThu\rJan 9\r\rR1,\rR2\r\r\r\rBlinding eye diseases\rSight restoration approaches \u0026amp; challenges\r\r\r\r\rHW1\r\r\r\r\r2\rTue\rJan 14\r\rR3\r\r\r\rFundamentals of neuroscience\rThe visual system\r\r\r\r\r\r\r\rThu\rJan 16\r\rR4\r\r\r\rComputational neuroscience\rIntroduction to Python\r\r\rHomework 1 (HW1) due by Sun, Jan 19, 11:59 pm.\r\r\r\r\rA1\t\r\rHW1\r\r\r3\rTue\rJan 21\r\rR5,\rR6\r\r\r\rRetina in health \u0026amp; disease\rRetinal prostheses\r\r\r\r\r\r\r\rThu\rJan 23\r\rR7\r\r\r\rIntroduction to pulse2percept in Python\rProject ideas: Discussion \u0026amp; brainstorming\r\r\r\rA2\r\r\r\r\r\r4\rTue\rJan 28\r\rR8\r\r\r\rVisual psychophysics for retinal prostheses\rPhosphene models: Scoreboard, axon map\r\r\r\r\r\r\r\rThu\rJan 30\r\r\rTeams present their project ideas \rTeam \u0026 project description (TPD) due by Sun, Feb 2, 11:59 pm.\r\r\r\r\r\rTPD\r\r\r5\rTue\rFeb 4\r\rR9\r\r\r\rCortical prostheses: approaches, challenges\rPhosphene models for cortical prostheses\r\r\r\r\rHW2\r\r\r\r\rThu\rFeb 6\r\r\r\rMid-quarter review\r\r\r\rA3\r\r\r\r\r\r6\rTue\rFeb 11\r\rR10,\rR11\r\r\r\rTraining \u0026amp; rehabilitation\rCortical plasticity \u0026amp; perceptual learning\r\r\r\r\r\r\r\rThu\rFeb 13\r\r\rGuest Visit: Jason Esterhuizen, ORION implantee\r \rA4\r\r\r\r\r\r7\rTue\rFeb 18\r\rR12, \rR13\r\r\r\rImproving visual outcomes in bionic eye technologies\rAdvanced stimulation strategies\r\r\r\r\r\r\r\rThu\rFeb 20\r\rR14\r\r\r\rOptimizing electrical stimulation in an artificial retina\r\r\rHomework 2 (HW2) due by Sun, Feb 23, 11:59 pm.\r\r\r\r\r\rHW2\r\r\r8\rTue\rFeb 25\r\rR15, \rR16\r\r\r\rScene representation for future bionic eye technologies\rAdvanced encoding methods\r\r\r\r\r\r\r\rThu\rFeb 27\r\r\rTeams present project progress\r\r\r\r\r\r9\rTue\rMar 3\r\rTeams work on projects -- Instructor out of the country\r\r\r\r\r\rThu\rMar 5\r\rTeams work on projects -- Instructor out of the country\r\r\r\r\r\r\r10\rTue\rMar 10\r\rR17\r\r\rGuest Lecture: Dr. Noelle Stiles, USC/Caltech\r\r\r\r\r\r\rThu\rMar 12\r\rR18\r\r\r\rOutlook: Future of bionic vision\rAlternatives to brain-computer interfaces\r\r\rProject report (PR) \u0026amp; source code (SC) due Sun, Mar 15, 11:59 pm.\r\r\r\r\r\rPR\u0026amp;SC\r\r11\rTue\rMar 17\r\rTeams make their final project presentations\r\r\r\r\r\r\rCourse Requirements \u0026amp; Grading Your final grade will be determined as follows:\n 15% Class participation and attendance:  Students are expected to attend all class sessions and actively participate in class discussions and activities. If a student must miss a session, they should email the instructor beforehand. Each student will be allowed 3 excused absences (no detailed explanation required) before their absence will start to negatively affect their participation grade. However, late arrivals and unexcused absences will most definitely have a negative effect on a student\u0026rsquo;s participation grade.   30% Homework assignments:  10% Homework 1 20% Homework 2   55% Final project implementation, documentation, and presentation  5% Project idea presentation (1 slide) 10% Project progress presentation (2 slides: what have you done, what\u0026rsquo;s left to do) 20% Project final presentation 20% Project final report (+5% extra credit if project shows promise of turning into a publication)    Lateness Policy All assignments are due at 11:59:59 pm on the scheduled due date, typically a Sunday (timestamp of the online submission system).\n Each student will be allowed 3 \u0026ldquo;late days\u0026rdquo; over the course of the quarter for which lateness will not be penalized. Late days cannot be applied to project deadlines. Late days may be applied to one or both homework assignments: Anything turned in between 12:00:00 am and 11:59:59 pm the next day is one day late; every day thereafter that an assignment is late, including weekends and holidays, counts as an additional late day. Absolutely no late work will be accepted after the deadline if you have used up all your late days. If you\u0026rsquo;re not done on time, you must turn in what you have to receive partial credit. There will be no exceptions from this rule. No exceptions will be made for the final project report.  Please make sure you understand this policy.\nFinal Project In lieu of a final exam, students will conduct a programming project (team size ≤ 3). The goal of the project is to gain hands-on experience working on open research questions in bionic vision using tools and methods best suited to their scientific background.\nAll projects must address a research question and have a programming component. Students are free to use any programming language and development environment they choose. Building a project based on pulse2percept is encouraged (especially for students with relatively little programming experience) but is by no means required. Reproducing key research findings in the literature is allowed. No pure literature reviews, please.\nProjects that show promise of turning into a publication will receive extra credit.\nStudents will present their project to the rest of the class during finals week. In addition, students will submit a write-up of their project and hand in their source code (see Milestones).\nThe project will be evaluated based on the:\n originality/novelty of the idea technical strength of the work (emphasis on the research, not the programming expertise) organization, clarity, and style of the project report effort and completeness of the work (normalized by the number of team members)  Project Milestones    Date Time Deliverable due     Thu, Jan 23 9:00 am Students start forming teams and discussing project ideas in class.   Thu, Jan 30 9:00 am Teams present their project ideas in class.   Sun, Feb 2 11:59 pm Teams submit a project title and 2-3 sentence project description.   Thu, Feb 27 9:00 am Teams present their project progress in class.   Sun, Mar 15 11:59 pm Teams hand in their final project report and all source code.   Tue, Mar 17  Teams make their final project presentations in class.    Students are encouraged to discuss ideas with the instructors, so that feedback can be incorporated early in the process.\nLate days cannot be used on these project deadlines.\nProject Presentation Teams will present their project via Zoom on Tue, Mar 17.\nEach team will have 20 mins to present (+5 mins for Questions \u0026amp; Answers). Sign up for a time slot here.\nBefore the meeting, decide who will host the slides/demo. This person will share their screen during the meeting. Other team members can choose to be physically present with the person sharing the screen or simply log in from their own computer.\nThere are at least two strategies to present your work:\n Strategy A: Follow the outline of your report  Introduction, Methods, Results, Discussion   Strategy B: Top-down  Give an overview of the project\u0026rsquo;s end result Follow with a detailed discussion of the various features/techniques    Make sure to address the challenges you faced and how you overcame them! What have you learned?\nEvery student in the team must say something.\nProject Report Each team will also submit a write-up of their project:\n Use the CHI Extended Abstracts template Structure your report like a short research paper (~4 pages):  Abstract: ~150 words Introduction (1-2 paragraphs)  What did you study and why?   Related work (1/2 page)  Brief summary of the relevant literature. Make sure to point out gaps in the literature that your project is trying to address.   Methods (1-2 pages)  First paragraph: Describe the big-picture idea behind your system/model/approach. Subsections: Walk the reader through all the steps/features (with pictures/schematics).   Results (1-2 pages)  Structure based on research question(s) and/or experiments. Have 2-3 figures to support your claims. Explain each figure and summarize the findings.   Discussion (1/2 page)  First sentence: Summarize your findings. Discuss: What does it all mean? What have you learned? Future work?      When you\u0026rsquo;re done, zip up the PDF/DOC together with all your source code and upload the zip file to GauchoSpace.\nDon\u0026rsquo;t forget to submit your source code.\nAcademic Integrity The University of California has formal policies related to academic integrity.\nAny act of academic dishonesty, such as cheating or plagiarism, will result in a University disciplinary action and an \u0026ldquo;F\u0026rdquo; in this course. In addition to academic integrity, I also expect everyone in this class to treat their fellow students and course staff with respect.\nBasic Needs If you are facing any challenges securing food or housing and believe this may affect your performance in the class, you are urged to meet with a Food Security and Calfresh Advocate who is aware of the broad variety of resources that UCSB has to offer (see their drop-in hours at food.ucsb.edu). You are also urged to contact the professor if you are comfortable doing so.\nPlease visit food.ucsb.edu for additional resources including Calfresh, the AS Food Bank, and more.\n","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"e575d5ab26bf85a2b9d88aa8cefe5cd2","people":null,"permalink":"https://bionicvisionlab.org/teaching/2020-winter-cs291i/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/teaching/2020-winter-cs291i/","section":"teaching","summary":"This graduate course will introduce students to the multidisciplinary field of bionic vision, with an emphasis on both the computer science and neuroscience of the field.","title":"CS-291I: Bionic Vision","type":"teaching"},{"categories":[],"content":"","date":1570742503,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570742503,"objectID":"01d43ae4db26724f7e05489e59bab7d8","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-optimal-surgical-placement/","publishdate":"2019-10-10T14:21:43-07:00","relpermalink":"/publications/2019-optimal-surgical-placement/","section":"publications","summary":"We systematically explored the space of possible implant configurations to make recommendations for optimal intraocular positioning of Argus II.","title":"Model-based recommendations for optimal surgical placement of epiretinal implants","type":"publications"},{"categories":null,"content":"Despite the increasing clinical and commercial use of retinal implants, the perceptual experience of sight recovery (SR) patients is surprisingly poorly understood.\nA common misconception in the field is that each electrode in an array can be thought of as a ‘pixel’ in an image; to generate a complex visual experience, one then simply needs to turn on the right combination of pixels.\nHowever, almost all SR technologies are likely to suffer from perceptual distortions and subsequent loss of information due to interactions between the technology and the underlying neurophysiology.\nThe goal of this project is to characterize these distortions psychophysically, and to develop a computational model that predicts what a patient should see for any given input stimulus.\n","date":1570060800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570060800,"objectID":"ba5fa69f72b3505988d005912a425275","people":null,"permalink":"https://bionicvisionlab.org/research/0-visual-modeling/","publishdate":"2019-10-03T00:00:00Z","relpermalink":"/research/0-visual-modeling/","section":"research","summary":"Clinical studies have demonstrated that the vision provided by current SR devices differs substantially from normal sight.","title":"What would the world look like with a bionic eye?","type":"research"},{"categories":null,"content":"Our lack of understanding of multi-electrode interactions severely limits current stimulation protocols. For example, current Argus II protocols simply attempt to minimize electric field interactions by maximizing phase delays across electrodes using ‘time-multiplexing’. The assumption is that single-electrode percepts act as atomic ‘building blocks’ of patterned vision. However, these building blocks often fail to assemble into more complex percepts.\nThe goal of this project is therefore to develop new stimulation strategies that minimize perceptual distortions.\n","date":1569974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569974400,"objectID":"63a49ce091f31ff634ace90a3b7c5471","people":null,"permalink":"https://bionicvisionlab.org/research/1-optimize-stimulation/","publishdate":"2019-10-02T00:00:00Z","relpermalink":"/research/1-optimize-stimulation/","section":"research","summary":"Rather than predicting perceptual distortions, one needs to solve the inverse problem: What is the best stimulus to generate a desired visual percept?","title":"How can we design more effective stimulation strategies?","type":"research"},{"categories":null,"content":"Embedding a computational model that can predict the perceptual distortions encountered by sight restoration (SR) patients in virtual reality (VR) will enable sighted subjects to act as virtual patients in real-world tasks. This will allow us to test novel stimulation strategies in high-throughput experiments. Strategies that result in good VR performance will then be validated in real SR patients.\nFor example, rather than aiming to ‘restore natural vision’, there is potential merit in borrowing computer vision algorithms as preprocessing techniques to maximize the usefulness of prosthetic vision. Edge enhancement and contrast maximization are already routinely used in Argus II. In the future, more sophisticated techniques such as low-level image enhancements and visual saliency based transforms could further improve visual performance.\n","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"5d07c563c9daf78e1945a87f9ab55a11","people":null,"permalink":"https://bionicvisionlab.org/research/2-virtual-patients/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/research/2-virtual-patients/","section":"research","summary":"Novel stimulation strategies can be tested on sighted subjects viewing a simulation of prosthetic vision in virtual/augmented reality.","title":"How can virtual patients improve performance of real sight recovery patients?","type":"research"},{"categories":null,"content":"","date":1563321600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563321600,"objectID":"a3097d298d06cb569e35f87e6e81a170","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-data-driven-models-human-neuroscience-neuroengineering/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publications/2019-data-driven-models-human-neuroscience-neuroengineering/","section":"publications","summary":"In this review, we provide an accessible primer to modern modeling approaches and highlight recent data-driven discoveries in the domains of neuroimaging, single-neuron and neuronal population responses, and device neuroengineering.","title":"Data-driven models in human neuroscience and neuroengineering","type":"publications"},{"categories":[],"content":"A new article appeared in PCMag to celebrate the inauguration of the Bionic Vision Lab at UCSB:\n Bionic vision might sound like science fiction, but Dr. Michael Beyeler is working on just that.\n  Originally from Switzerland, Dr. Beyeler is wrapping up his postdoctoral fellow at the University of Washington before moving to the University of California Santa Barbara this fall to head up the newly formed Bionic Vision Lab in the Departments of Computer Science and Psychological \u0026amp; Brain Sciences.\n  We spoke with him about this \u0026ldquo;deep fascination with the brain\u0026rdquo; and how he hopes his work will eventually be able to restore vision to the blind. Here are edited and condensed excerpts from our conversation.\n Read the full article here.\n","date":1562689740,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562689753,"objectID":"00c60f07f684f1b3efbeb9fa775c1b01","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/post/2019-07-pcmag/","publishdate":"2019-07-09T09:29:00-07:00","relpermalink":"/post/2019-07-pcmag/","section":"post","summary":"Michael Beyeler recently sat down with PCMag to talk about bionic vision and his move to UC Santa Barbara.","title":"PCMag: Restoring vision with bionic eyes - no longer science fiction","type":"post"},{"categories":null,"content":"","date":1561593600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561593600,"objectID":"386c91297fe76d33fc00b9225d6ec9dd","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-neural-correlates-sparse-coding-dimensionality-reduction/","publishdate":"2019-06-27T00:00:00Z","relpermalink":"/publications/2019-neural-correlates-sparse-coding-dimensionality-reduction/","section":"publications","summary":"Brains face the fundamental challenge of extracting relevant information from high-dimensional external stimuli in order to form the neural basis that can guide an organism's behavior and its interaction with the world. One potential approach to addressing this challenge is to reduce the number of variables required to represent a particular input space (i.e., dimensionality reduction). We review compelling evidence that a range of neuronal responses can be understood as an emergent property of nonnegative sparse coding (NSC)—a form of efficient population coding due to dimensionality reduction and sparsity constraints.","title":"Neural correlates of sparse coding and dimensionality reduction","type":"publications"},{"categories":null,"content":"","date":1561334400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561334400,"objectID":"9aade570f250a8bdf7d19bf2115101b8","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-axon-map-model/","publishdate":"2019-06-24T00:00:00Z","relpermalink":"/publications/2019-axon-map-model/","section":"publications","summary":"We show that the perceptual experience of retinal implant users can be accurately predicted using a computational model that simulates each individual patient’s retinal ganglion axon pathways.","title":"A model of ganglion axon pathways accounts for percepts elicited by retinal implants","type":"publications"},{"categories":null,"content":"","date":1558310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558310400,"objectID":"c444c103408be4d6a1dbd752616ec318","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-biophysical-model-axonal-stimulation/","publishdate":"2019-05-20T00:00:00Z","relpermalink":"/publications/2019-biophysical-model-axonal-stimulation/","section":"publications","summary":"To investigate the effect of axonal stimulation on the retinal response, we developed a computational model of a small population of morphologically and biophysically detailed retinal ganglion cells, and simulated their response to epiretinal electrical stimulation. We found that activation thresholds of ganglion cell somas and axons varied systematically with both stimulus pulse duration and electrode-retina distance. These findings have important implications for the improvement of stimulus encoding methods for epiretinal prostheses.","title":"Biophysical model of axonal stimulation in epiretinal visual prostheses","type":"publications"},{"categories":null,"content":"","date":1557446400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557446400,"objectID":"7364a8adf91ea84cc0fbbd0c04424708","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-retinal-sheet-transplants/","publishdate":"2019-05-10T00:00:00Z","relpermalink":"/publications/2019-retinal-sheet-transplants/","section":"publications","summary":"A Commentary on: Detailed Visual Cortical Responses Generated by Retinal Sheet Transplants in Rats with Severe Retinal Degeneration by Foik, A. T., Lean, G. A., Scholl, L. R., McLelland, B. T., Mathur, A., Aramant, R. B., et al. (2018). J. Neurosci. 38, 10709–10724. doi: 10.1523/JNEUROSCI.1279-18.2018","title":"Commentary: Detailed visual cortical responses generated by retinal sheet transplants in rats with severe retinal degeneration","type":"publications"},{"categories":null,"content":"","date":1531440000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531440000,"objectID":"096961db4e57e2fb4d3906e8230e49cf","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2018-carlsim4/","publishdate":"2018-07-13T00:00:00Z","relpermalink":"/publications/2018-carlsim4/","section":"publications","summary":"We have developed CARLsim 4, a user-friendly SNN library written in C++ that can simulate large biologically detailed neural networks. Improving on the efficiency and scalability of earlier releases, the present release allows for the simulation using multiple GPUs and multiple CPU cores concurrently in a heterogeneous computing cluster. Benchmarking results demonstrate simulation of 8.6 million neurons and 0.48 billion synapses using 4 GPUs and up to 60x speedup for multi-GPU implementations over a single-threaded CPU implementation, making CARLsim 4 well-suited for large-scale SNN models in the presence of real-time constraints.","title":"CARLsim 4: An open source library for large scale, biologically detailed spiking neural network simulation using heterogeneous clusters","type":"publications"},{"categories":null,"content":"","date":1503360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503360000,"objectID":"b5e80da46501c93df7df8c6fb3c5fc7f","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2017-learning-to-see-again/","publishdate":"2017-08-22T00:00:00Z","relpermalink":"/publications/2017-learning-to-see-again/","section":"publications","summary":"The goal of this review is to summarize the vast basic science literature on developmental and adult cortical plasticity with an emphasis on how this literature might relate to the field of prosthetic vision.","title":"Learning to see again: Biological constraints on cortical plasticity and the implications for sight restoration technologies","type":"publications"},{"categories":null,"content":"","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"0f9bbe69fd665667e284936ab7bda6e7","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2017-pulse2percept/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/publications/2017-pulse2percept/","section":"publications","summary":"*pulse2percept* is an open-source Python simulation framework used to predict the perceptual experience of retinal prosthesis patients across a wide range of implant configurations.","title":"pulse2percept: A Python-based simulation framework for bionic vision","type":"publications"},{"categories":null,"content":"","date":1470009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470009600,"objectID":"6010a0be9a85e86c6ad356a4d230a9e2","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2016-sparse-decomposition-model/","publishdate":"2016-08-01T00:00:00Z","relpermalink":"/publications/2016-sparse-decomposition-model/","section":"publications","summary":"Using a dimensionality reduction technique known as non-negative matrix factorization, we found that a variety of medial superior temporal (MSTd) neural response properties could be derived from MT-like input features. The responses that emerge from this technique, such as 3D translation and rotation selectivity, spiral tuning, and heading selectivity, can account for a number of empirical results. These findings (1) provide a further step toward a scientific understanding of the often nonintuitive response properties of MSTd neurons; (2) suggest that response properties, such as complex motion tuning and heading selectivity, might simply be a byproduct of MSTd neurons performing dimensionality reduction on their inputs; and (3) imply that motion perception in the cortex is consistent with ideas from the efficient-coding and free-energy principles.","title":"3D visual response properties of MSTd emerge from an efficient, sparse population code","type":"publications"},{"categories":null,"content":"","date":1448928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448928000,"objectID":"de49b660f9fc238f3af998f4dfc28f79","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2015-gpu-visually-guided-robot-navigation/","publishdate":"2015-12-01T00:00:00Z","relpermalink":"/publications/2015-gpu-visually-guided-robot-navigation/","section":"publications","summary":"We present a cortical neural network model for visually guided navigation that has been embodied on a physical robot exploring a real-world environment. The model includes a rate based motion energy model for area V1, and a spiking neural network model for cortical area MT. The model generates a cortical representation of optic flow, determines the position of objects based on motion discontinuities, and combines these signals with the representation of a goal location to produce motor commands that successfully steer the robot around obstacles toward the goal. This study demonstrates how neural signals in a model of cortical area MT might provide sufficient motion information to steer a physical robot on human-like paths around obstacles in a real-world environment.","title":"A GPU-accelerated cortical neural network model for visually guided robot navigation","type":"publications"},{"categories":null,"content":"","date":1436659200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1436659200,"objectID":"4c7bedf1cb0d806fe2aece390417d28c","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2015-carlsim3/","publishdate":"2015-07-12T00:00:00Z","relpermalink":"/publications/2015-carlsim3/","section":"publications","summary":"We have developed CARLsim 3, a user-friendly, GPU-accelerated SNN library written in C/C++ that is capable of simulating biologically detailed neural models. The present release of CARLsim provides a number of improvements over our prior SNN library to allow the user to easily analyze simulation data, explore synaptic plasticity rules, and automate parameter tuning. In the present paper, we provide examples and performance benchmarks highlighting the library's features.","title":"CARLsim 3: A user-friendly and highly optimized library for the creation of neurobiologically detailed spiking neural networks","type":"publications"},{"categories":null,"content":"","date":1401580800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1401580800,"objectID":"9dfaef9074cb247761c6511079679203","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2014-vision-road-lane-detection/","publishdate":"2014-06-01T00:00:00Z","relpermalink":"/publications/2014-vision-road-lane-detection/","section":"publications","summary":"This paper presents an integrative approach to ego-lane detection that aims to be as simple as possible to enable real-time computation while being able to adapt to a variety of urban and rural traffic scenarios. The approach at hand combines and extends a road segmentation method in an illumination-invariant color image, lane markings detection using a ridge operator, and road geometry estimation using RANdom SAmple Consensus (RANSAC). The power and robustness of this algorithm has been demonstrated in a car simulation system as well as in the challenging KITTI data base of real-world urban traffic scenarios.","title":"Vision-based robust road lane detection in urban environments","type":"publications"},{"categories":null,"content":"","date":1391558400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1391558400,"objectID":"a53663b6b62012e138a0743d6e6dfef2","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2014-snn-pattern-motion/","publishdate":"2014-01-20T00:00:00Z","relpermalink":"/publications/2014-snn-pattern-motion/","section":"publications","summary":"We present a two-stage model of visual area MT that we believe to be the first large-scale spiking network to demonstrate pattern direction selectivity. In this model, component-direction-selective (CDS) cells in MT linearly combine inputs from V1 cells that have spatiotemporal receptive fields according to the motion energy model of Simoncelli and Heeger. Pattern-direction-selective (PDS) cells in MT are constructed by pooling over MT CDS cells with a wide range of preferred directions. Responses of our model neurons are comparable to electrophysiological results for grating and plaid stimuli as well as speed tuning.","title":"Efficient spiking neural network model of pattern motion selectivity in visual cortex","type":"publications"},{"categories":null,"content":"","date":1390176000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1390176000,"objectID":"da2f3225cbcc97db91c2933db3c0c0ee","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2014-gpgpu-accelerated-simulation-parameter-tuning/","publishdate":"2014-01-20T00:00:00Z","relpermalink":"/publications/2014-gpgpu-accelerated-simulation-parameter-tuning/","section":"publications","summary":"We describe a simulation environment that can be used to design, construct, and run spiking neural networks (SNNs) quickly and efficiently using graphics processing units (GPUs). We then explain how the design of the simulation environment utilizes the parallel processing power of GPUs to simulate large-scale SNNs and describe recent modeling experiments performed using the simulator. Finally, we present an automated parameter tuning framework that utilizes the simulation environment and evolutionary algorithms to tune SNNs.","title":"GPGPU accelerated simulation and parameter tuning for neuromorphic applications","type":"publications"},{"categories":null,"content":"","date":1385856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1385856000,"objectID":"e469311b24ad43d62ae7a26f056d1942","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2013-categorization-mnist-stdp/","publishdate":"2013-12-01T00:00:00Z","relpermalink":"/publications/2013-categorization-mnist-stdp/","section":"publications","summary":"We present a large-scale model of a hierarchical spiking neural network (SNN) that integrates a low-level memory encoding mechanism with a higher-level decision process to perform a visual classification task in real-time. The model consists of Izhikevich neurons and conductance-based synapses for realistic approximation of neuronal dynamics, a spike-timing-dependent plasticity (STDP) synaptic learning rule with additional synaptic dynamics for memory encoding, and an accumulator model for memory retrieval and categorization. The full network, which comprised 71,026 neurons and approximately 133 million synapses, ran in real-time on a single off-the-shelf graphics processing unit (GPU). The network achieved 92% correct classifications on MNIST in 100 rounds of random sub-sampling, which is comparable to other SNN approaches and provides a conservative and reliable performance metric. Additionally, the model correctly predicted reaction times from psychophysical experiments. Because of the scalability of the approach and its neurobiological fidelity, the current model can be extended to an efficient neuromorphic implementation that supports more generalized object recognition and decision-making architectures found in the brain.","title":"Categorization and decision-making in a neurobiologically plausible spiking network using a STDP-like plasticity rule","type":"publications"},{"categories":null,"content":"","date":1288569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1288569600,"objectID":"1df3e4d282d890015a5345a70810e5d6","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2010-exploring-olfactory-networks/","publishdate":"2010-11-01T00:00:00Z","relpermalink":"/publications/2010-exploring-olfactory-networks/","section":"publications","summary":"Olfactory stimuli are represented in a high-dimensional space by neural networks of the olfactory system. While a number of studies have illustrated the importance of inhibitory networks within the olfactory bulb or the antennal lobe for the shaping and processing of olfactory information, it is not clear how exactly these inhibitory networks are organized to provide filtering and contrast enhancement capabilities. In this work the aim is to study the topology of the proposed networks by using software simulations and hardware implementation. While we can study the dependence of the activity on each parameter of the theoretical models with the simulations, it is important to understand whether the models can be used in robotic applications for real-time odor recognition. We present the results of a linear simulation, a spiking simulation with I\u0026F neurons and a real-time hardware emulation using neuromorphic VLSI chips.","title":"Exploring olfactory sensory networks: Simulations and hardware emulation","type":"publications"}]